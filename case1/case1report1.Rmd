---
title: "Case 1"
author: "Nathaniel Brown, Annie Tang, William Yang"
date: "September 1, 2017"
output: html_document
---

we are interested in estimating dose response curve!
therefore we want to treat dose as a continuous variable.
does response curve vary across labs? estimate the variation between labs.

group i in different lab should not be treated as the same group.
do not use group! it provides no new information.

2 recommended approaches to analyze data are as:
  freq mixed effects (lme4::lmer)
  bayesian hierarchical (rstan, rjags)


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2); library(dplyr); library(reshape2); library(knitr)
```

### Exploratory Data Analysis 

After loading the data, we noticed that there were several rows with missing (NA) values for weights. We decided to only remove the rows with missing values for blot weight or body weight (4 rows total). Since our main response variable of interest was blot weight, we decided to keep the observations with missing wet weight. 

```{r, warning=FALSE}
dat <- read.table("alllabs.txt", header = TRUE, stringsAsFactors = FALSE, na.strings = ".")
dat <- dat[!(is.na(dat$blot) | is.na(dat$body)),]
weights <- dat[,c("body", "wet", "blot")]
weights_long <- melt(weights, id = "body")
```

Initially, we plotted wet and blotted weights across all observations, and we noticed that the weights seemed to be separated into two groups.

```{r, warning=FALSE}
ggplot(data = weights_long, 
       mapping = aes(x=body, y=value, color=variable)
      ) + geom_point()
```

But after color coding the chart by protocol (A,B,C,D) we noticed that the A & B protocols were grouped together and the C & D protocols were grouped together. In class, we were told that two experimental models were used, one for juvenile female rats and another for adult female ovariectomized rats; we were also told that each experimental model was associated with two protocols each. Based on this knowledge, we suspect that the gap in observed weights is likely due to A & B protocols consisting of juvenile (i.e. smaller) rats. 

```{r, warning=FALSE}
grpweights <- dat[,c("body", "blot","lab", "proto", "group")]

ggplot(data = grpweights, 
       mapping = aes(x=body, y=blot, color=proto)
) + geom_point()
```

We then created boxplots of body, wet, and blotted weight observations across each lab. The data appeared to be right skewed, so we took the log of the response variable and replotted. The resulting boxplots appear to be more normally distributed. It also appears that all the weights vary by lab. It is also worthwhile to note that body weight and uterus (wet, blot) weight are not measured on the same scale, but we were not given the units used for either. So, the relative size of each box plot is not to scale. 


```{r, warning=FALSE}
labweights <- dat[,c("body", "wet", "blot", "lab")]
labweights_long <- melt(labweights, id="lab")
ggplot(data = labweights_long,
       mapping = aes(x=lab, y=value, color = variable)) +
  geom_boxplot() + 
  ylab("weight") + 
  theme(axis.text.x = element_text(angle = 90, hjust=1))
ggplot(data = labweights_long,
       mapping = aes(x=lab, y=log(value), color = variable)) + 
  geom_boxplot() + 
  ylab("log(weight)") + 
  theme(axis.text.x = element_text(angle = 90, hjust=1))
```

Next, we plotted the body, wet, and blotted weight observations according to the protocol that was applied. Again, we logged each of the weight values to account for data skew. There appears to be more variation in uterus weights and body weight. 

```{r, warning=FALSE}
protoweights <- dat[,c("body", "wet", "blot", "proto")]
protoweights_long <- melt(protoweights, id="proto")
ggplot(data = protoweights_long,
       mapping = aes(x=proto, y=log(value), color = variable)) + 
  geom_boxplot() +
  ylab("log(weight)") + 
  xlab("protocol")

```

Upon plotting all combinations of dosages across groups, we notice a couple of trends. First, we see that as the quantity of dose 1 increases without dose 2, the log blotted weight increases. Secondly, when dose 2 is introduced, an increase in quantity of dose 2 leads to a decrease in log blotted weight.

```{r, warning=FALSE}
dosage_groups <-  dat %>% 
                  group_by(group) %>% 
                  summarize(dose1 = unique(dose1), 
                            dose2 = unique(dose2),
                            A = sum(proto == "A"),
                            B = sum(proto == "B"),
                            C = sum(proto == "C"),
                            D = sum(proto == "D")
                  ) %>% as.data.frame()
kable(dosage_groups)
doselabels <- apply(dosage_groups[,c("dose1", "dose2")], 1, paste, collapse = ",") %>% paste("(", ., ")", sep="")

ggplot(data = dat ,
       mapping=aes(x=as.factor(group), y=log(blot))) + 
  geom_boxplot() + 
  ylab("log(blotted uterus weight)") + 
  xlab("(dose1, dose2)") + 
  scale_x_discrete(labels = doselabels) + 
  theme(axis.text.x = element_text(angle = 45, hjust=1))

```

### Possible Approaches to Analysis

#### First Approach: Univariate Normal


$$
log(y_{\text{wet}}) \sim N(log(\mu_{\text{wet}}), \sigma^2)
\\
log(y_{\text{blot}}) \sim N(log(\mu_{\text{blot}}), \sigma^2)
$$


```{r, warning=FALSE}
par(mfrow=c(1,2))
ggplot(dat,
       aes(x=log(wet))) + geom_histogram()
ggplot(dat,
       aes(x=log(blot))) + geom_histogram()
ggplot(dat[dat$proto %in% c("A", "B"),],
       aes(x=log(wet))) + geom_histogram()
ggplot(dat[dat$proto %in% c("C", "D"),],
       aes(x=log(blot))) + geom_histogram()
par(mfrow=c(1,1))
```
This naive approach does not account for lab-to-lab heterogeneity. This results in an underestimation of the uncertainty in $\hat{\mu}$.

#### Second Approach: Multivariate Normal
$$
y_i, \mu \in M_{\text{mx1}}( \Re)
\\
\Sigma \in M_{\text{nxn}}( \Re)
\\ 
log(y_i) \sim \text{MVNorm}(log(\mu), \Sigma)
$$

```{r, warning=FALSE}
labweights <- dat[,c("blot", "lab")]
names(labweights)
labweights_long <- melt(labweights, id="lab")
ggplot(data = labweights_long,
       mapping = aes(x=lab, y=log(value))
       ) + geom_boxplot() + theme(axis.text.x = element_text(angle=90))
```

In this model,$y_i$ is a vector of $m$ observations from lab $i$. Each lab has an approximate normal distribution with a different mean.

This accounts for heterogeneity between labs, however, as you add more structure (blocking factors, covariates, etc.) to the model, the covariance matrix becomes more complicated, and maximum likelihood estimation becomes unwieldy. Also, this model estimates parameters only for these $\n$ groups, and does not generalize to new groups.


#### Third Approach: Mixed Effects

$$
y_i, \mu \in M_{\text{mx1}}( \Re)
\\
y_{ij} \sim \text{Norm}(\mu_i, \sigma^2_i)
\\
\mu_i \sim \text{Norm}(\mu, \psi^2)
\\
\sigma_i^2 \sim \text{IG}(\nu/2, \nu\sigma^2/2)
$$

Let $y_i$ be a $mx1$ vector of observations, where $i$ indicates the lab and $m$ is equal to the number of observations within lab $i$. So, $y_{ij}$ represents an individual observation for subject j within lab i. We apply a Gaussian assumption here and say that each observation is normally distributed for some $\mu_i$ and $\sigma^2_i$ . 

We then add a random effect on $\mu_i$, so $\text{Norm}(\mu, \psi^2)$ gives us a population distribution characterizing lab to lab variability. This allows our model to be generalizable to future labs. Furthermore, when calculating the MLE of each $\mu_i$, there is less variability because they are pulled in toward the grand mean $\mu$. This introduces bias, but the decrease in varaiance reults in an overall benefit for the MSE. 


#### Fourth Approach: Bayesian Hierarchical Model
$$
\mu \sim \text{Norm}(\mu_0, \tau_0)
\\
\psi^2 \sim \text{IG}(\eta_0/2, \eta_0\psi_0/2)
\\
\sigma_i^2 \sim \text{IG}(\nu_0/2, \nu_0\sigma_0^2/2)
\\
\mu_i \sim \text{Norm}(\mu, \psi^2)
\\
y_{ij} \sim \text{Norm}(\mu_i, \sigma_i^2)
$$

As an alternative to the classical mixed effects model, hierarchical modeling offers a Bayesian, but essentially equivalent approach. 


---
title: "Case 1"
author: "Nathaniel Brown, Annie Tang, William Yang"
date: "September 13, 2017"
output: html_document
---

```{r setup, include=FALSE, echo=FALSE}
set.seed(440)
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2); library(dplyr); library(reshape2); library(knitr); library(rstan); library(lme4)
```

```{r, warning=FALSE, echo=FALSE}
dat <- read.table("alllabs.txt", header = TRUE, stringsAsFactors = FALSE, na.strings = ".")
dat <- dat[!(is.na(dat$blot) | is.na(dat$body)),]
ndat <- nrow(dat)
trainrows <- sample(x=1:ndat, size = ceiling(0.75*ndat))
testrows <- setdiff(1:ndat, trainrows)
dat_train <- dat[trainrows,]
dat_test <- dat[testrows,]
```

Initially, we plotted the blotted weights by body weights, and we noticed that the body weights seemed to be separated into two groups.

```{r, warning=FALSE, echo=FALSE}
weights <- dat[,c("body", "blot")]
ggplot(data = weights, 
       mapping = aes(x=body, y=blot)) + 
  geom_point() + 
  labs(title="Blotted Weight vs. Body Weight",
       x="Body Weight",
       y="Blotted Weight"
       ) +
  theme(plot.title = element_text(hjust = 0.5))
```

But after color coding the chart by protocol (A,B,C,D) we noticed that the A & B protocols were grouped together and the C & D protocols were grouped together. In class, we were told that two experimental models were used, one for juvenile female rats and another for adult female ovariectomized rats; we were also told that each experimental model was associated with two protocols each. Based on this knowledge, we suspect that the gap in observed weights is likely due to A & B protocols consisting of juvenile (i.e. smaller) rats. 

```{r, warning=FALSE, echo=FALSE}
grpweights <- dat[,c("body", "blot","lab", "proto", "group")]

ggplot(data = grpweights, 
       mapping = aes(x=body, y=blot, color=proto)) + 
  geom_point() +
  labs(title="Blotted Weight vs. Body Weight",
       x="Body Weight",
       y="Blotted Weight",
       color="Protocol"
       ) +
  theme(plot.title = element_text(hjust = 0.5))
```

We then created boxplots of body and blotted weight observations across each lab. The data appeared to be right skewed, so we took the log of the response variable and replotted. The resulting boxplots appear to be more normally distributed. It also appears that all the weights vary by lab. It is also worthwhile to note that body weight and uterus weight are not measured on the same scale, but we were not given the units used for either. So, the relative size of each box plot is not to scale. 


```{r, warning=FALSE, echo=FALSE}
labweights <- dat[,c("body", "blot", "lab")]
labweights_long <- melt(labweights, id="lab")
ggplot(data = labweights_long,
       mapping = aes(x=lab, y=value, color = variable)) +
  geom_boxplot() + 
  labs(title = "Weight by Lab",
       x = "Lab",
       y = "Weight",
       color = "Weighed Object") +
  theme(axis.text.x = element_text(angle = 90, hjust=1),
        plot.title = element_text(hjust = 0.5))

ggplot(data = labweights_long,
       mapping = aes(x=lab, y=log(value), color = variable)) + 
  geom_boxplot() + 
  labs(title = "log(Weight) by Lab",
       x = "Lab",
       y = "log(Weight)",
       color = "Weighed Object") +
  theme(axis.text.x = element_text(angle = 90, hjust=1),
        plot.title = element_text(hjust = 0.5))

```

Next, we plotted the body and blotted weight observations according to the protocol that was applied. Again, we logged each of the weight values to account for data skew.

```{r, warning=FALSE, echo=FALSE}
protoweights <- dat[,c("body", "blot", "proto")]
protoweights_long <- melt(protoweights, id="proto")
ggplot(data = protoweights_long,
       mapping = aes(x=proto, y=log(value), color = variable)) + 
  geom_boxplot() +
  labs(title = "log(Weight) by Protocol",
       x = "Protocol",
       y = "log(Weight)",
       color = "Weighed Object") +
  theme(plot.title = element_text(hjust = 0.5))

```

Upon plotting all combinations of dosages across groups (each group represents a different combination of dose 1 and dose 2), we notice a couple of trends. First, we see that as the quantity of dose 1 increases without dose 2, the log blotted weight increases. Secondly, when dose 2 is introduced, an increase in quantity of dose 2 leads to a decrease in log blotted weight.

```{r, warning=FALSE, echo=FALSE}
dosage_groups <-  dat %>% 
                  group_by(group) %>% 
                  summarize(dose1 = unique(dose1), 
                            dose2 = unique(dose2),
                            A = sum(proto == "A"),
                            B = sum(proto == "B"),
                            C = sum(proto == "C"),
                            D = sum(proto == "D")
                  ) %>% as.data.frame()
doselabels <- apply(dosage_groups[,c("dose1", "dose2")], 1, paste, collapse = ", ") %>% paste("(", ., ")", sep="")

ggplot(data = dat ,
       mapping=aes(x=as.factor(group), y=log(blot))) + 
  geom_boxplot() + 
  labs(title = "log(Blotted Weight) by Dosage",
       x = "Combination of (Dose 1, Dose 2)",
       y = "log(Blotted Weight)") +
  scale_x_discrete(labels = doselabels) + 
  theme(axis.text.x = element_text(angle = 45, hjust=1),
        plot.title = element_text(hjust = 0.5))
kable(dosage_groups)

```



### Initial Model-Fitting Results
<!-- should contiain:

exploratory analysis???
code for model
description of how analysis was conducted
problems that arose
goodness-of-fit

-->
#### First Approach: Univariate Normal


$$
log(y) \sim \text{Norm}(\mu , \sigma^2)
$$

```{r fig.width=15, fig.height=5, echo=FALSE}
mod1 <- lm(log(blot) ~ 1, data = dat)
resid_title <- "Residuals vs. Fitted Values"
qq_title <- "Normal Quantile-Quantile Plot"
hist_title <- "Histogram of Residuals"
par(mfrow=c(1,3))
logmeans <- data.frame(blot = log(dat$blot), lmean =mean(log(dat$blot)) )
plot(mod1,1)
plot(mod1,2)
hist(mod1$residuals, breaks=25, main = hist_title, col="gray", xlab="")
par(mfrow=c(1,1))
```

This naive approach assumes the blotted weight follows a normal distribution with a mean centered around the mean of the log blotted weight (`r round(mean(log(dat$blot)),4)`) and constant variance. The diagnostic plots below show that the same value is predicted for each input, the quantiles of the residuals do not follow a normal distrbution, and that the residuals are bimodal. We believe bimodality may be caused by the separation of rats into juvenille and adult protocols.

#### Second Approach: Multivariate Normal
$$
y_i, \mu \in M_{n_i \times 1}( \Re)
\\
\Sigma \in M_{n \times n}( \Re)
\\ 
log(y_i) \sim \text{MVNorm}(\mu, \Sigma)
$$

In this model,$y_i$ is a vector of $n_i$ observations from lab $i$. It assumes that the log blotted weights of each lab follow approximately normal distributions with a their own means.

```{r, echo=FALSE}
mu_hat <- dat %>% group_by(lab) %>% summarize(blot = mean(blot)) %>% as.data.frame() 
lab_names <- mu_hat[["lab"]]
mu_hat <- mu_hat %>% '[['(2) %>% t()
colnames(mu_hat) <- lab_names
mod2 <- lm(log(mu_hat) ~ 1)
```

We provide the diagnosis plots for the first lab, `Basf`, and we put the others in Appendix 1.1, since R does not support plotting for multivariate regression models.
```{r fig.width=15, fig.height=5, echo=FALSE}
plot_mvn <- function(mod = NA, lab_name = NA){
  lab_ind <- which(lab_names == lab_name)
  newdat <- dat %>% filter(lab == lab_name) %>% select(blot) %>% log()
  fitvals <- predict(mod, newdata=newdat)[,lab_ind]
  resids <- fitvals - newdat[[1]]
  plot(fitvals, resids, main=paste(resid_title, ": ", lab_name, " Lab", sep=""), xlab = "Fitted Values", ylab = "Residuals"); abline(h=0)
  qqnorm(resids, main=paste(qq_title, ": ", lab_name, " Lab", sep="")); qqline(resids) 
  hist(resids, breaks=25, main=paste(hist_title, ": ", lab_name, " Lab", sep=""), xlab = "Residuals", col="gray")
}

par(mfrow=c(1,3))
plot_mvn(mod2, "Basf")
par(mfrow=c(1,1))
```

The diagnostic plots for this model indicate that the model predicts the same fitted value for each lab, and that the residual quantiles do not follow a normal distribution. For the `Basf` lab, the histogram of residuals shows left skew. These same problems, along with multimodality of the residuals, are present for the diagnostic plots for the remaining labs in the Appendix. 

A weakness of this model is that, as you add more structure (blocking factors, covariates for dosage, etc.) to the model, the covariance matrix becomes more complicated, and maximum likelihood estimation becomes unwieldy. The poor fit of this model indicates that we should control for more than just the lab effect, so we consider a mixed effects model.


#### Third Approach: Mixed Effects

$$
y_{ij} \sim \beta_{0,i} + \beta_{1,i}x_{ij,d_1} + \beta_{2,i}x_{ij,d_2} + \beta_{3,i}x_{ij,p_B} + \beta_{4,i}x_{ij,p_C} + \beta_{5,i}x_{ij,p_D} + \beta_{6,i}x_{ij,log(w)} + \epsilon
\\
\beta_{0:6,i} \sim N(\mu_{0:6,i}, \sigma^2_{0:6,i})
\\
\epsilon \sim N(0, \sigma^2)
$$

Let $y_{ij}$ be the observation for log(blotted uterus weight) for subject $x_{ij}$, the $j$th individual in lab $i$. $x_{ij,d_1}$ and $x_{ij,d_2}$ are the values of dose1 and dose2 for subject $x_{ij}$. $x_{ij,p_B}$, $x_{ij,p_C}$, and $x_{ij,p_D}$ are dummy variables for which protocol $x_{ij}$ was subjected to. $x_{ij,log(w)}$ is the log(body weight) for $x_{ij}$. We make the Gaussian assumption that the coefficients, $\beta$, are normally distributed according to some $\mu_i$ and $\sigma_i$. We add a random effect on all $\beta_{0:5,i}$ to account for lab-to-lab variability in the intercepts and slopes on the blotted weight for the different dosages and protocols.

We start at a reduced form of this model and augment it to its full form after initial analyses.

##### Analysis
```{r, echo=FALSE}
plot_lmer <- function(mod){
  par(mfrow=c(1,3))
  fitvals <- exp(predict(mod, dat_train))
  resids <- summary(mod)[["residuals"]]

  plot(fitvals, resids, main = resid_title, xlab = "Fitted Values", ylab = "Residuals"); abline(h=0)
  qqnorm(resids, main = qq_title)
  hist(resids, main = hist_title, xlab="Residuals", col = "gray")
  par(mfrow=c(1,1))
}
```


```{r, echo=FALSE}
# RANDOM INTERCEPT MODEL
m1.reduced <- lmer(log(blot) ~ dose1 + dose2 + (1|lab), data=dat_train, REML = FALSE)
m1.full <- lmer(log(blot) ~ dose1 + dose2 + proto + (1|lab), data=dat_train, REML = FALSE)
nova <- anova(m1.reduced, m1.full)
```

In our analysis, we choose to add a random effect for the lab variable, in order to account for lab-to-lab heterogeneity. Essentially, this allows us to avoid violating an independence assumption by assuming a different baseline response for each lab. First, we model these differences between individual labs by assuming random intercepts for each lab. We first include only dose1 and dose2 as fixed effects, then introduce proto as a fixed effect after confirming through anova ($p$ < 2.2e-16, $\chi^2$=`r round(nova[["Chisq"]][length(nova[["Chisq"]])], 4)`) that it is a significant predictor. The summary statistics of this model are shows in the table below:

```{r, echo = FALSE}
lmer_list <- function(mod){
  
  fixeffmeans <- summary(mod)[["coefficients"]][,1]
  fixeffsd <- summary(mod)[["coefficients"]][,2]
  randeffmeans_all <- getME(mod, "theta")
  numdots <- sapply(names(randeffmeans_all), gregexpr, pattern="." , fixed=TRUE) %>% sapply(length)
  randeffmeans <- randeffmeans_all[which((numdots) == 1)]
  randeffvar <- diag(summary(mod)[["varcor"]][["lab"]])
  residsd <- sigma(mod)
  
  fnamz <- names(fixeffmeans)
  rnamz <- names(randeffvar)
  namz <- c("Mean Fixed Effects", "Variance Fixed Effects", "Mean Random Effects", "Variance Random Effects", "Residual Variance")

  names(randeffmeans) <- rnamz

  fixefftab <- data.frame(fixeffmeans,fixeffsd^2) %>% round(4)
  names(fixefftab) <- c("Mean Fixed Effects", "Variance Fixed Effects")
  randefftab <- data.frame(randeffmeans,randeffvar) %>% round(4)
  names(randefftab) <- c("Mean Random Effects", "Variance Random Effects")
  residtab <- data.frame(residsd^2) %>% round(4)
  names(residtab) <- c("Variance")
  rownames(residtab) <- c("Residual")
  
  return(list(fixefftab, randefftab, residtab))  
}
L <- lmer_list(m1.full)
kable(L[[1]])
kable(L[[2]])
kable(L[[3]])
```


With this full model, we see that the variability due to lab is 0.028 (in terms of variance), and variability due to non-lab sources is 0.193. And when we take a look at the fixed effects, we see that an increase in the amount of dose1 corresponds to an increase (0.142 units) in the response variable, log(blot). Furthermore, an increase in the amount of dose2 corresponds to a decrease (-0.519 units) in the response variable. Protocols B, C, and D all lead to an increase in the response variable, relative to protocol A. The diagnostic plots below show that this model fits better than the previous two. Although the residual variance decreases as the fitted values increase, the quantiles of the residuals are approximately normal.

```{r fig.width=15, fig.height=5, echo=FALSE}

par(mfrow = c(1,3))
plot_lmer(m1.full)
par(mfrow = c(1,1))
```


In this random intercept model, we account for baseline differences between labs, but we also assume that the effects of doses is the same for each lab. After plotting the log(blot) versus dose by lab, we see that this is not a valid assumption to make since the lines are clearly not parallel. So we introduce a random slope model. Now, dose1 and dose2 can have varying slopes.


```{r, echo=FALSE}

ggplot(data=dat,aes(x=dose1,y=log(blot),color=lab)) + geom_point() + geom_line() + labs(x="dose 1", y="log(blot)", title="Dose 1 vs. log(blot)") + theme(plot.title = element_text(hjust = 0.5))
ggplot(data=dat,aes(x=dose2,y=log(blot),color=lab)) + geom_point() + geom_line() + labs(x="dose 2", y="log(blot)", title="Dose 2 vs. log(blot)") + theme(plot.title = element_text(hjust = 0.5))

# RANDOM SLOPE MODEL
m2 <- lmer(log(blot) ~ proto + (dose1 + dose2 + 1|lab), data=dat_train, REML=FALSE)
m3 <- lmer(log(blot) ~ proto + (I(1/(dose1+0.5)) + dose2 + 1|lab), data=dat_train, REML=FALSE)
#m3 is a much better fit FYI. normal qq is actually a straight line!
m4 <- lmer(log(blot) ~ proto + log(body) + (I(1/(dose1+1/2)) + dose2 + 1|lab), data=dat_train, REML=FALSE)
# anova to show addition of log(body) is significant 
nova <- anova(m3, m4)
```

After adding the random slopes, we transformed dose 1 using a reciprocal transformation and added body weight as a predictor in order to have the best fitting model. We evaluate this model using summary statistics, diagnostic plots, and out-of-sample predictive accuracy, which we evaluate using Mean Absolute Error $(\text{MAE} = E[|y - \hat{y}|])$ and Root Mean Squared Error $(\text{RMSE} = \sqrt{E[(y - \hat{y})^2]})$. Root Mean Squared Error penalizes more for extreme errors, while Mean Absolute Error simply averages all of the errors.


```{r, fig.height=5, fig.width=15, echo=FALSE}
L2 <- lmer_list(m4)
kable(L2[[1]]); kable(L2[[2]]); kable(L2[[3]])

plot_lmer(m4)

#root mean squared error penalizes more for extreme error
rms_err <- function(actual, predicted){
  error <- actual - predicted
  return(sqrt(mean((error)^2)))
}
 
#absolute error weighs all error equally
abs_err <- function(actual, predicted){
  error <- actual - predicted
  mean(abs(error))
}
 
compute_errs <- function(mod, test = dat_test){
  preds <- exp(predict(mod, test))
  absolute <- abs_err(test$blot, preds) %>% round(4)
  rootmean <- rms_err(test$blot, preds) %>% round(4)
  return(list(abs_err = absolute, rms_err = rootmean))
}

random_dose_errs <- compute_errs(m4)
fixed_dose_errs <- compute_errs(m1.full)

tab <- t(data.frame(x=as.numeric(random_dose_errs),y=as.numeric(fixed_dose_errs)))
colnames(tab) <- c("MAE","RMSE")
rownames(tab) <- c("Random Dose + Transformations", "Fixed Dose")
kable(tab)
```

We see that the variability due to sources other than the random effects is 0.0797 (decreased from 0.193). Also, the diagnostic plots improved, although it is notable that the residual variance decreases for larger fitted values. The fixed dose model is also much worse at predicting than the random dose model with transformations.

```{r, echo=FALSE}
#simulate lmer random effects
sim_params <- function(mod, nsim = 1000){
  
  fixeffmeans <- summod[["fixef"]] %>% round(4)
  randeffmeans_all <- getME(mod, "theta") %>% round(4)
  numdots <- sapply(names(randeffmeans_all), gregexpr, pattern="." , fixed=TRUE) %>% sapply(length)
  randeffmeans <- randeffmeans_all[which((numdots) == 1)]
  randeffsd <- diag(summary(mod)[["varcor"]][["lab"]]) %>% round(4)
  
  sims <- array(NA, c(nsim, length(randeffsd)))
  for(i in 1:ncol(sims)){
    sims[,i] <- rnorm(nrow(sims), mean = randeffmeans[i], sd = randeffsd[i])
  }
  
  plot(x=c(-10,10), y=c(-10,10), type="n") #abline(intercept, slope)
  for(j in 1:nrow(sims))
  abline(sims[j,1], sims[j,2], col="gray")
}
```

<!--
#### Fourth Approach: Bayesian Hierarchical Model
$$
y_i \in M_{n_i \times 1}( \Re)
\\
\mu \sim \text{Norm}(\mu_0, \tau_0^2)
\\
\psi^2 \sim \text{IG}(\eta_0/2, \eta_0\psi_0^2/2)
\\
\mu_i \sim \text{Norm}(\mu, \psi^2)
\\
\theta_1 \sim \text{Norm}(\theta_{01}, \tau_{01}^2)
\\
\theta_2 \sim \text{Norm}(\theta_{02}, \tau_{02}^2)
\\
\theta_3 \sim \text{Norm}(\theta_{03}, \tau_{03}^2)
\\
\sigma_1^2 \sim \text{IG}(\nu_{01}/2, \nu_{01}\sigma_{01}^2/2)
\\
\sigma_2^2 \sim \text{IG}(\nu_{02}/2, \nu_{02}\sigma_{02}^2/2)
\\
\sigma_3^2 \sim \text{IG}(\nu_{03}/2, \nu_{03}\sigma_{03}^2/2)
\\
\beta_{1i} \sim \text{Norm}(\theta_{1}, \sigma^2_{1})
\\
\beta_{2i} \sim \text{Norm}(\theta_{2}, \sigma^2_{2})
\\
\beta_{3i} \sim \text{Norm}(\theta_{3}, \sigma^2_{3})
\\
\epsilon_{ij} \sim \text{Norm}(0, \sigma^2)
\\
y_{ij} = \mu_i + \beta_{1i}x_{1ij} + \beta_{2i}x_{2ij} + \beta_{3i}x_{1ij}x_{2ij} + \epsilon_{ij}
$$

As an alternative to the classical mixed effects model, hierarchical modeling offers a Bayesian, but essentially equivalent approach. We also added fixed linear effects for the dosages, since the purpose of this study is to investigate the variation of the dosage response curve in different labs. $x_{kij}$ represents the amount of dose $k$ on patient $ij$. The interaction effect is included because dose 2 appears only at a certain level of dose 1.

#STEALING RSTAN CODE
```{r}
stanstring <- "
data {
  int<lower=0> J;          // # schools
  real y[J];               // estimated treatment
  real<lower=0> sigma[J];  // std err of effect
}
  parameters {
  real theta[J];           // school effect
  real mu;                 // mean for schools
  real<lower=0> tau;       // variance between schools
}
model {
  theta ~ normal(mu, tau);
  y ~ normal(theta, sigma);
}
"


datalist <- list(
  y = c(28, 8, -3, 7, -1, 1, 18, 12),
  sigma = c(15, 10, 1, 11, 9, 11, 10, 18)
)
datalist$J = length(datalist[["y"]])
# schools <- stan(model_code = stanstring, 
#                 data = datalist,
#                 pars = c("theta", "mu", "tau"),
#                 iter = 1000, chains = 1
#)
```

-->
### Conclusion

Because the dose 1 effect has such a high variance relative to the mean, our model shows that the bioassay being studied does not measure a consistent response to dosage across labs.

### Contributions

Nathaniel Brown made the visualizations for this report. He also organized the relevant files in a Github repository for the group to access and edit. Annie Tang compiled the group work done on EDA into a .rmd and wrote the accompanying explanations for the EDA and approaches to analysis. William Yang helped pair on EDA analysis and identify approaches to handle the data. Approaches to analysis were a joint effort by all members of the group. Nathanial implemented analysis for the univariate normal and multivariate normal approaches. Implementation and analysis of the mixed effects model was a joint effort by all members of the group. 

### Appendix

#### 1.1 Multivariate Normal Diagnosis Plots
```{r fig.height=5, fig.width=15, echo = FALSE}
par(mfrow = c(1,3))
for(name in lab_names[-1]){
  plot_mvn(mod2, name)
}
```


<!--         THESE ARE NOT MERGE CONFLICTS

TODO:
  make the ggplots smaller
  
we are interested in estimating dose response curve!
therefore we want to treat dose as a continuous variable.
does response curve vary across labs? estimate the variation between labs.

group i in different lab should not be treated as the same group.
do not use group! it provides no new information.

2 recommended approaches to analyze data are as:
  freq mixed effects (lme4::lmer)
  bayesian hierarchical (rstan, rjags)
  
AT MINIMUM you should have (1+proto+dose|labs)
random inter, proto, dose, that all "interact" with lab

our final analysis should be on variation of intercepts and slopes
how we summarize it is up to us
Jonathan suggests looking at joint dist of (dose,lab) then 
then sample a bunch of intercepts and slopes from dist
then plotting them all together and making sure slopes aren't highly varying and criss-crossed
(you don't have to do it this way, but this is Jonathan's way)

also, correlations come from summary function?
-->
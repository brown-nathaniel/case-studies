---
title: "Case 1"
author: "Nathaniel Brown, Annie Tang, William Yang"
date: "September 6, 2017"
output: html_document
---

<!--
we are interested in estimating dose response curve!
therefore we want to treat dose as a continuous variable.
does response curve vary across labs? estimate the variation between labs.

group i in different lab should not be treated as the same group.
do not use group! it provides no new information.

2 recommended approaches to analyze data are as:
  freq mixed effects (lme4::lmer)
  bayesian hierarchical (rstan, rjags)
-->

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2); library(dplyr); library(reshape2); library(knitr)
```


```{r, warning=FALSE}
dat <- read.table("alllabs.txt", header = TRUE, stringsAsFactors = FALSE, na.strings = ".")
dat <- dat[!(is.na(dat$blot) | is.na(dat$body)),]
```

<<<<<<< HEAD
Initially, we plotted the blotted weights by body weights, and we noticed that the body weights seemed to be separated into two groups.

```{r, warning=FALSE}
weights <- dat[,c("body", "blot")]
ggplot(data = weights, 
       mapping = aes(x=body, y=blot)) + 
  geom_point() + 
  labs(title="Blotted Weight vs. Body Weight",
       x="Body Weight",
       y="Blotted Weight"
       ) +
  theme(plot.title = element_text(hjust = 0.5))
```

But after color coding the chart by protocol (A,B,C,D) we noticed that the A & B protocols were grouped together and the C & D protocols were grouped together. In class, we were told that two experimental models were used, one for juvenile female rats and another for adult female ovariectomized rats; we were also told that each experimental model was associated with two protocols each. Based on this knowledge, we suspect that the gap in observed weights is likely due to A & B protocols consisting of juvenile (i.e. smaller) rats. 

```{r, warning=FALSE}
grpweights <- dat[,c("body", "blot","lab", "proto", "group")]

ggplot(data = grpweights, 
       mapping = aes(x=body, y=blot, color=proto)) + 
  geom_point() +
  labs(title="Blotted Weight vs. Body Weight",
       x="Body Weight",
       y="Blotted Weight",
       color="Protocol"
       ) +
  theme(plot.title = element_text(hjust = 0.5))
```

We then created boxplots of body and blotted weight observations across each lab. The data appeared to be right skewed, so we took the log of the response variable and replotted. The resulting boxplots appear to be more normally distributed. It also appears that all the weights vary by lab. It is also worthwhile to note that body weight and uterus weight are not measured on the same scale, but we were not given the units used for either. So, the relative size of each box plot is not to scale. 


```{r, warning=FALSE}
labweights <- dat[,c("body", "blot", "lab")]
labweights_long <- melt(labweights, id="lab")
ggplot(data = labweights_long,
       mapping = aes(x=lab, y=value, color = variable)) +
  geom_boxplot() + 
  labs(title = "Weight by Lab",
       x = "Lab",
       y = "Weight",
       color = "Weighed Object") +
  theme(axis.text.x = element_text(angle = 90, hjust=1),
        plot.title = element_text(hjust = 0.5))

ggplot(data = labweights_long,
       mapping = aes(x=lab, y=log(value), color = variable)) + 
  geom_boxplot() + 
  labs(title = "log(Weight) by Lab",
       x = "Lab",
       y = "log(Weight)",
       color = "Weighed Object") +
  theme(axis.text.x = element_text(angle = 90, hjust=1),
        plot.title = element_text(hjust = 0.5))

```

Next, we plotted the body and blotted weight observations according to the protocol that was applied. Again, we logged each of the weight values to account for data skew.

```{r, warning=FALSE}
protoweights <- dat[,c("body", "blot", "proto")]
protoweights_long <- melt(protoweights, id="proto")
ggplot(data = protoweights_long,
       mapping = aes(x=proto, y=log(value), color = variable)) + 
  geom_boxplot() +
  labs(title = "log(Weight) by Protocol",
       x = "Protocol",
       y = "log(Weight)",
       color = "Weighed Object") +
  theme(plot.title = element_text(hjust = 0.5))

```

Upon plotting all combinations of dosages across groups (each group represents a different combination of dose 1 and dose 2), we notice a couple of trends. First, we see that as the quantity of dose 1 increases without dose 2, the log blotted weight increases. Secondly, when dose 2 is introduced, an increase in quantity of dose 2 leads to a decrease in log blotted weight.
=======
### Initial Model-Fitting Results
<!-- should contiain:

exploratory analysis???
code for model
description of how analysis was conducted
problems that arose
goodness-of-fit

-->
#### First Approach: Univariate Normal


$$
log(y) \sim \text{Norm}(\mu , \sigma^2)
$$
```{r fig.width=15, fig.height=5}
mod1 <- lm(log(blot) ~ 1, data = dat)
par(mfrow=c(1,3))
logmeans <- data.frame(blot = log(dat$blot), lmean =mean(log(dat$blot)) )
plot(mod1,1) #resids vs fixed
plot(mod1,2) #normal qq
hist(mod1$residuals, breaks=25) #resids
par(mfrow=c(1,1))
```

This naive approach assumes the blotted weight follows a normal distribution with a mean centered around the mean log blotted weight (`r mean(log(dat$blot))`) constant variance. The diagnostic plots below show that the same value is predicted for each input, the quantiles of the data do not follow a normal distrbution, and that the residuals are bimodal. We believe bimodality may be caused by the separation of rats into children and adult protocols.

#### Second Approach: Multivariate Normal
$$
y_i, \mu \in M_{n_i \times 1}( \Re)
\\
\Sigma \in M_{n \times n}( \Re)
\\ 
log(y_i) \sim \text{MVNorm}(\mu, \Sigma)
$$

In this model,$y_i$ is a vector of $n_i$ observations from lab $i$. It assumes that the log blotted weights of each lab follow approximately normal distributions with a their own means.

```{r}

mu_hat <- dat %>% group_by(lab) %>% summarize(blot = mean(blot)) %>% as.data.frame() 
lab_names <- mu_hat[["lab"]]
mu_hat <- mu_hat %>% '[['(2) %>% t()
colnames(mu_hat) <- lab_names
mod2 <- lm(log(mu_hat) ~ 1)
```

We provide the diagnosis plots for the first lab, `Basf`, and the rest can be found in Appendix 1.1, since R does not support plotting for multivariate regression models.
```{r fig.width=15, fig.height=5}
basf_data <- dat %>% filter(lab == "Basf") %>% select(blot) %>% log()
fitvals <- predict(mod2, newdata=basf_data)[,1]
resids <- fitvals - basf_data[[1]]
par(mfrow=c(1,3))
plot(fitvals, resids); abline(h=0) #residuals vs fitted values
qqnorm(resids); qqline(resids) #normal qq plot
hist(resids, breaks=25) #distribution of residuals
par(mfrow=c(1,1))
```

The diagnostic plots for this model indicate that the model predicts the same fitted value for each input, and that the residual quantiles do not follow a normal distribution. For the first lab, the histogram of residuals is not bimodal like they are in the simpler $mod1$, but it does show left skew. These same problems, in addition to  multimodality of the residuals, are present for the diagnostic plots for the remaining labs in the Appendix. 

A weakness of this model is that, as you add more structure (blocking factors, covariates for dosage, etc.) to the model, the covariance matrix becomes more complicated, and maximum likelihood estimation becomes unwieldy. Also, this model estimates parameters only for these $n$ groups, and does not apply to new groups without recalculation.


#### Third Approach: Mixed Effects

$$
y_i \in M_{n_i \times 1}( \Re)
\\
\mu_i \sim \text{Norm}(\mu, \psi^2)
\\
\sigma_i^2 \sim \text{IG}(\nu/2, \nu\sigma^2/2)
\\
y_{ij} \sim \text{Norm}(\mu_i, \sigma^2_i)
$$

Let $y_i$ be a $n_i \times 1$ vector of observations, where $i$ indicates the lab and $n_i$ is equal to the number of observations within lab $i$. So, $y_{ij}$ represents an individual observation for subject $j$ within lab $i$. We apply a Gaussian assumption here and say that each observation is normally distributed for some $\mu_i$ and $\sigma^2_i$. 

We then add a random effect on $\mu_i$, so $\text{Norm}(\mu, \psi^2)$ gives us a population distribution characterizing lab-to-lab variability. This allows our model to be generalizable to future labs. Furthermore, when calculating the MLE of each $\mu_i$, there is less variability because they are pulled in toward the grand mean $\mu$. This introduces bias, but the decrease in varaiance reults in an overall benefit for the MSE. 

```{r}
View(dat)
library(lme4)
# add predictor for age group 
dat <- transform(dat, age = ifelse((proto == "A" | proto == "B"), "juvenile", "adult"))

# RANDOM INTERCEPT MODEL
m1.reduced <- lmer(log(blot) ~ dose1 + dose2 + (1|lab), data=dat, REML = FALSE)
summary(m1.reduced) 
m1.full <- lmer(log(blot) ~ dose1 + dose2 + age + (1|lab), data=dat, REML = FALSE)
summary(m1.full)
anova(m1.reduced, m1.full)
#Age group (juvenile versus adult) affected log(blot) weight (chi2=2211.7, p<2.2e-16), lowering log(blot) weight by 1.23277+-0.02(standard errors). 
coef(full) #coeficients with random intercepts 


# but effect of doses may be different across different labs
# RANDOM SLOPE MODEL
m2 <- lmer(log(blot) ~ age + (dose1 + dose2 + 1|lab), data=dat, REML=FALSE)
summary(m2)
m3 <- lmer(log(blot) ~ age + (dose1 + dose2|age) + (1|lab), data=dat, REML=FALSE)
summary(m3)


```

#### Fourth Approach: Bayesian Hierarchical Model
$$
y_i \in M_{n_i \times 1}( \Re)
\\
\mu \sim \text{Norm}(\mu_0, \tau_0^2)
\\
\psi^2 \sim \text{IG}(\eta_0/2, \eta_0\psi_0^2/2)
\\
\mu_i \sim \text{Norm}(\mu, \psi^2)
\\
\theta_1 \sim \text{Norm}(\theta_{01}, \tau_{01}^2)
\\
\theta_2 \sim \text{Norm}(\theta_{02}, \tau_{02}^2)
\\
\theta_3 \sim \text{Norm}(\theta_{03}, \tau_{03}^2)
\\
\sigma_1^2 \sim \text{IG}(\nu_{01}/2, \nu_{01}\sigma_{01}^2/2)
\\
\sigma_2^2 \sim \text{IG}(\nu_{02}/2, \nu_{02}\sigma_{02}^2/2)
\\
\sigma_3^2 \sim \text{IG}(\nu_{03}/2, \nu_{03}\sigma_{03}^2/2)
\\
\beta_{1i} \sim \text{Norm}(\theta_{1}, \sigma^2_{1})
\\
\beta_{2i} \sim \text{Norm}(\theta_{2}, \sigma^2_{2})
\\
\beta_{3i} \sim \text{Norm}(\theta_{3}, \sigma^2_{3})
\\
\epsilon_{ij} \sim \text{Norm}(0, \sigma^2)
\\
y_{ij} = \mu_i + \beta_{1i}x_{1ij} + \beta_{2i}x_{2ij} + \beta_{3i}x_{1ij}x_{2ij} + \epsilon_{ij}
$$

As an alternative to the classical mixed effects model, hierarchical modeling offers a Bayesian, but essentially equivalent approach. We also added fixed linear effects for the dosages, since the purpose of this study is to investigate the variation of the dosage response curve in different labs. $x_{kij}$ represents the amount of dose $k$ on patient $ij$. The interaction effect is included because dose 2 appears only at a certain level of dose 1.

### Contributions

Nathaniel Brown made the visualizations for this report. He also organized the relevant files in a Github repository for the group to access and edit. Annie Tang compiled the group work done on EDA into a .rmd and wrote the accompanying explanations for the EDA and approaches to analysis. William Yang helped pair on EDA analysis and identify approaches to handle the data. Approaches to analysis were a joint effort by all members of the group. 

### Appendix

#### 1.1 Multivariate Normal Diagnosis Plots
```{r fig.height=5, fig.width=15}
plot_mvn <- function(mod = NA, lab_name = NA){
  lab_ind <- which(lab_names == lab_name)
  newdat <- dat %>% filter(lab == lab_name) %>% select(blot) %>% log()
  fitvals <- predict(mod, newdata=newdat)[,lab_ind]
  resids <- fitvals - newdat[[1]]
  plot(fitvals, resids); abline(h=0) #residuals vs fitted values
  qqnorm(resids); qqline(resids) #normal qq plot
  hist(resids, breaks=25) #distribution of residuals
}
par(mfrow = c(1,3))
for(name in lab_names[-1]){
  plot_mvn(mod2, name)
}

```
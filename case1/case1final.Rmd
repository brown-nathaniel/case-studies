---
title: "Analyzing Rat Bioassays"
author: "Nathaniel Brown, Annie Tang, William Yang"
date: "September 13, 2017"
output:
  pdf_document: default
  html_document: default
  fig_caption: yes
---


```{r setup, include=FALSE, echo=FALSE}
set.seed(440)
knitr::opts_chunk$set(echo = FALSE)
library(ggplot2); library(dplyr); library(reshape2); library(knitr); library(rstan); library(lme4); library(mvtnorm); library(gridExtra)
```


```{r, warning=FALSE}
dat <- read.table("alllabs.txt", header = TRUE, stringsAsFactors = FALSE, na.strings = ".")
dat <- dat[!(is.na(dat$blot) | is.na(dat$body)),]

ndat <- nrow(dat)
trainrows <- sample(x=1:ndat, size = ceiling(0.75*ndat))
testrows <- setdiff(1:ndat, trainrows)
dat_train <- dat[trainrows,]
dat_test <- dat[testrows,]
```

### Introduction

  In this report, we analyze data from an international validation study to measure the effectiveness of the rat uterotrophic bioassay. The bioassay being studied attempts to measure the estrogenic effect of certain chemicals. The two chemicals used in this study have well known effects, so we would like to verify that the bioassay produces consistent results in rats that have been administered various dosages of the chemicals across two possible protocols. If the uterotrophic bioassay is an effective procedure for measuring the effects of these chemicals, then we expect to see consistent responses to various dosages across all labs and groupings.

### Methods

  To measure the consistency of the responses, we fit iterations of a linear mixed effects model on the provided dataset. The model is conditioned on the labs to account for lab-to-lab variability. Each iteration of the model differs slightly in transformations and conditioning of the predictors/responses until we arrive at a model that we deem most appropriate for the dataset. We then evaluate the final model to determine whether it predicts large variation in responses to the dosages between labs, or if it predicts a consistent measured response to the chemicals.

### Model-Fitting

$$
y_{ij} \sim \beta_{0,i} + \beta_{1,i}x_{ij,d_1} + \beta_{2,i}x_{ij,d_2} + \beta_{3,i}x_{ij,p_B} + \beta_{4,i}x_{ij,p_C} + \beta_{5,i}x_{ij,p_D} + \beta_{6,i}x_{ij,log(w)} + \epsilon
\\
\beta_{0:5,i} \sim N(\mu_{0:5,i}, \sigma^2_{0:5,i})
\\
\epsilon \sim N(0, \sigma^2)
$$

To fit the data, we used a mixed model, with fixed and random effects. Let $y_{ij}$ be the observed log(blotted uterus weight) for subject $x_{ij}$, the $j$th individual in lab $i$. $x_{ij,d_1}$ and $x_{ij,d_2}$ are the values of dose1 and dose2 for subject $x_{ij}$. $x_{ij,p_B}$, $x_{ij,p_C}$, and $x_{ij,p_D}$ are dummy variables indicating which protocol $x_{ij}$ was subjected to. $x_{ij,log(w)}$ is the log(body weight) for $x_{ij}$. Body weight and uterus weight are log-transformed to account for the right skew in the data (Fig. 1). We make the Gaussian assumption that the coefficients, $\beta$, are normally distributed according to some $\mu_i$ and $\sigma_i$. We add a random effect on all $\beta_{0:5,i}$ to account for the lab-to-lab variability in the intercepts and slopes of the blotted weight (Fig. 2). The summary statistics of the model described above can be found on Table 1.

We start at a reduced form of this model and augment it to its full form after initial analyses.

```{r fxns}
expsq <- function(x){
  exp(x^2)
}
plot_lmer <- function(mod, parmfrow = NA, untrans_y = exp){
  if(mean(is.na(parmfrow) > 0)){
    par(mfrow = c(1,1))
  }else{
    par(mfrow = parmfrow)
  }
  fitvals <- untrans_y(predict(mod, dat_train))
  resids <- summary(mod)[["residuals"]]

  plot(fitvals, resids, main = "Residuals vs. Fitted Values", xlab = "Fitted Values", ylab = "Residuals"); abline(h=0)
  qqnorm(resids, main = "Normal Quantile-Quantile Plot")
  hist(resids, main = "Histogram of Residuals", xlab="Residuals", col = "gray")
  
  continuouseffects <- grep("(dose)|(body)", colnames(coef(mod)[[1]]), value=TRUE)

  #for cases when we interact with proto
  continuouseffects <- gsub(":", "')*", continuouseffects)
  continuouseffects <- lapply(
    strsplit(continuouseffects, "proto"),
    function(l){
      if(length(l) > 1){
        return(paste0("(proto=='", l[2]))
      }
      return(l)
    }
  )
  X <- apply(as.matrix(continuouseffects), 1,
        function(x){
          with(dat_train, eval(parse(text = x)))
        }
  )
  for(c in 1:ncol(X)){
    if(grepl("proto", continuouseffects[c])){
      plot(X[,c][X[,c] > 0], resids[X[,c] > 0], main = "Residuals vs. Predictor" , xlab = continuouseffects[c], ylab = "Residuals")
    }else{
      plot(X[,c], resids, main = "Residuals vs. Predictor" , xlab = continuouseffects[c], ylab= "Residuals")
    }
  }
  par(mfrow=c(1,1))
}


#root mean squared error penalizes more for extreme error
rms_err <- function(actual, predicted){
  error <- actual - predicted
  return(sqrt(mean((error)^2)))
}
 
#absolute error weighs all error equally
abs_err <- function(actual, predicted){
  error <- actual - predicted
  mean(abs(error))
}
 
compute_errs <- function(mod, test = dat_test, untrans_y = exp){
  preds <- untrans_y(predict(mod, test))
  absolute <- abs_err(test$blot, preds) %>% round(4)
  rootmean <- rms_err(test$blot, preds) %>% round(4)
  return(list(abs_err = absolute, rms_err = rootmean))
}

lmer_list <- function(mod){
  
  fixeffmeans <- summary(mod)[["coefficients"]][,1]
  fixeffsd <- summary(mod)[["coefficients"]][,2]
  # randeffmeans_all <- getME(mod, "theta")
  # numdots <- sapply(names(randeffmeans_all), gregexpr, pattern="." , fixed=TRUE) %>% sapply(length)
  # randeffmeans <- randeffmeans_all[which((numdots) == 1)]
  #randeffmeans <- ranef(mod)[["lab"]] %>% apply(2,mean)
  randeffmeans <- t(ranef(mod)[["lab"]]) 
  randeffvar <- diag(summary(mod)[["varcor"]][["lab"]])
  residsd <- sigma(mod)
  
  #names(randeffmeans) <- names(randeffvar)

  fixefftab <- data.frame(fixeffmeans,fixeffsd^2)
  names(fixefftab) <- c("mean", "variance")
  #randefftab <- data.frame(randeffmeans,randeffvar)
  #names(randefftab) <- c("mean", "variance")
  residtab <- data.frame(residsd^2)
  names(residtab) <- c("variance")
  rownames(residtab) <- c("residual")
  
  return(list(fixed = fixefftab, randommeans = randeffmeans, randomvars = randeffvar, residual = residtab))  
}

format_lmer_list <- function(L = NA){

  colnames(L$fixed) <- c("Mean Fixed Effects", "Variance Fixed Effects")
  colnames(L$residual) <- c("Residual Variance")
  L <- lapply(L, round, 4)
  return(L)
}

simdose1curves <- function(mod, nsim = 1000, untrans_y = exp, lab = NA, showoriginaldata = FALSE){
  
  #simulated data
  L <- lmer_list(mod)
  MEANS <- c(L[["randommeans"]]["(Intercept)", lab], L[["randommeans"]][grep("dose1", rownames(L[["randommeans"]])), lab])
  
  COR_full <- attr(VarCorr(mod)[[1]], "correlation")

  dose1ind <- grep("dose1", rownames(COR_full))
  interind <- grep("Inter", rownames(COR_full))
  
  COR <- COR_full[c(interind,dose1ind), c(interind,dose1ind)]
  sdxy <- prod(attr(VarCorr(mod)[[1]], "stddev")[c(interind,dose1ind)])
  #cov(x,y) = cor(x,y)*sd(x)sd(y)
  COV <- COR * sdxy
  sims <- rmvnorm(nsim, mean = MEANS, sigma = COV)
  dose1sims <- sims[,2]
  labsims <- sims[,1]
  
  dose1sims <- c(MEANS[2], dose1sims) #the first dose mean is just the 
  labsims <- c(MEANS[1], labsims) #the first dose mean is just the 
  nsim <- nsim + 1
  
  #constant data
  protoeffect <- 0 #just assume baseline protocol
  dose2 <- 0 
  dose2trans <- eval(parse(text = grep("dose2", rownames(L$randommeans), value=T))) #in case dose2 needs to be transformed
  dose2effect <- dose2trans*L$randommeans[grep("dose2", rownames(L$randommeans)), lab]
  fixedintereffect <- L$fixed["(Intercept)","mean"]
  protoeffect <- 0 
  body <- (mean(dat_train$body))
  bodyeffect <- log(body)*(L$fixed[grep("body", rownames(L$fixed)), "mean"])
  
  dose1 <- seq(0,10, 0.1)
  dose1trans <- eval(parse(text = grep("dose1", rownames(L$randommeans), value=T)))
  dose1effect <- (apply(t(dose1trans), 2, '*', dose1sims))
  
  response <- matrix(untrans_y(fixedintereffect + protoeffect + bodyeffect + dose2effect + labsims + dose1effect), nrow = nsim)

  plot(0,0, type="n", xlim = c(min(dose1), max(dose1)), ylim = c(0,500), xlab = "Dose 1", ylab="Blotted Uterus Weight", main = paste("Dose 1 Response Curve for", lab, "Lab"))
  for(r in 2:nsim){ #for each simulation...
    lines(dose1, response[r,], col=rgb(.9,.9,.9))
  }
  if(showoriginaldata){
    points(x=dat$dose1, y=dat$blot)
  }
  lines(dose1, response[1,], col="black") #plot the mean line in black
}

```


```{r models, echo=FALSE}
# RANDOM SLOPE MODEL
m1 <- lmer(log(blot) ~ proto + log(body) + (dose1 + dose2 + 1|lab), data=dat_train, REML=FALSE)

m2 <- lmer(log(blot) ~ proto + log(body) + (I(1/(dose1+1/2)) + dose2 + 1|lab), data=dat_train, REML=FALSE)

m3 <- lmer(sqrt(log(blot)) ~ proto + log(body) + (I(1/(dose1+1/2)) + dose2 + 1|lab), data=dat_train, REML=FALSE)

m4 <- lmer(log(blot) ~ proto + log(body) + (I(1/(dose1+1/2)) + dose2 + 1|lab), data=dat_train, REML=FALSE)

L1 <- lmer_list(m1)
L2 <- lmer_list(m2)
L3 <- lmer_list(m3)
L4 <- lmer_list(m4)

errs1 <- compute_errs(m1)
errs2 <- compute_errs(m2)
errs3 <- compute_errs(m3, untrans_y=expsq)
errs4 <- compute_errs(m4, untrans_y=expsq)

```

\par

```{r, echo=FALSE, fig1, fig.cap="Log Transformations of Weights", fig.height=5, fig.width=15}
labweights <- dat[,c("body", "blot", "lab")]
labweights_long <- melt(labweights, id="lab")
g1 <- ggplot(data = labweights_long,
       mapping = aes(x=lab, y=value, color = variable)) +
  geom_boxplot() + 
  labs(title = "Weight by Lab",
       x = "Lab",
       y = "Weight",
       color = "Weighed Object") +
  theme(axis.text.x = element_text(angle = 90, hjust=1),
        plot.title = element_text(hjust = 0.5))

g2 <- ggplot(data = labweights_long,
       mapping = aes(x=lab, y=log(value), color = variable)) + 
  geom_boxplot() + 
  labs(title = "log(Weight) by Lab",
       x = "Lab",
       y = "log(Weight)",
       color = "Weighed Object") +
  theme(axis.text.x = element_text(angle = 90, hjust=1),
        plot.title = element_text(hjust = 0.5))
grid.arrange( g1, g2, ncol=2)

```

\par

```{r, fig2, fig.cap="Lab-to-Lab Variability in Intercepts and Slopes", echo=FALSE, fig.height=5, fig.width=15, warning=FALSE}

graph1 <- ggplot(data=dat,aes(x=dose1,y=log(blot),color=lab)) + geom_point() + geom_line() + labs(x="dose 1", y="log(blot)", title="Dose 1 vs. log(blot)") + theme(plot.title = element_text(hjust = 0.5))
graph2 <- ggplot(data=dat,aes(x=dose2,y=log(blot),color=lab)) + geom_point() + geom_line() + labs(x="dose 2", y="log(blot)", title="Dose 2 vs. log(blot)") + theme(plot.title = element_text(hjust = 0.5))

grid.arrange( graph1, graph2, ncol=2)
```

\par

```{r tab1}
L1 <- format_lmer_list(L1)
# kable(L1[[1]], caption = "Summary Statistics of Initial Model")
# #kable(L1[[2]]) %>% kable_styling(font_size = 7)
# kable(L1[[3]])
# kable(L1[[4]])
```



```{r fig3, echo=FALSE, fig.height=10, fig.width=15, fig.cap="Diagnostic Plots of Initial Model"}
plot_lmer(m1, c(2,3))
```

Among the problems in these plots is the nonlinearity in the Residuals vs. Predictor plot for dose1. To counter this, we transformed dose 1 by the reciprocal of (dose1 + 1/2) (we add a small number to dose because we cannot take the reciprocal of zero). We evaluate this transformed model using summary statistics, diagnostic plots, and out-of-sample predictive accuracy, which we measure using Mean Absolute Error $(\text{MAE} = E[|y - \hat{y}|])$ and Root Mean Squared Error $(\text{RMSE} = \sqrt{E[(y - \hat{y})^2]})$. Root Mean Squared Error penalizes more for extreme errors, while Mean Absolute Error simply averages all of the errors. The results are in the following tables and figures:


```{r tab2}
L2 <- format_lmer_list(L2)
# kable(L2[[1]], caption = "Summary Statistics of Transformed Dose 1")
# #kable(L2[[2]])
# kable(L2[[3]])
# kable(L2[[4]])
```

```{r fig4, fig.height=10, fig.width=15, fig.cap="Diagnostic Plots of Model with Transformed Dose 1"}
plot_lmer(m2, parmfrow = c(2,3))
```

```{r tab3}
errtab <- t(data.frame(x=as.numeric(errs1),y=as.numeric(errs2), z=as.numeric(errs3)))
colnames(errtab) <- c("MAE","RMSE")
rownames(errtab) <- c("Initial", "Reciprocal Dose 1", "Transformed Dose 1 and Uterus Weight")
kable(errtab[-3,], caption = "Predictive Error of First Two Models")

```

**comment comment comment**. Another problem with these residual plots is the slight arching in the Residuals vs. Fitted Values. To counteract this, we added a square root transformation to the response. **well then again we might not*** The results are below:


```{r tab4}
L3 <- format_lmer_list(L3)
# kable(L3[[1]], caption = "")
# #kable(L3[[2]])
# kable(L3[[3]])
# kable(L3[[4]])
```

```{r fig5}
plot_lmer(m3, parmfrow = c(2,3), expsq)
```

```{r tab5}
kable(errtab, caption = "Predictive Error of All Models")
```

This is our best-fitting mixed model we could fit. **maybe. it looks like sqrt log blot improves residual plot but worsens prediction**

### Results

#INCOMPLETE 
The plot below samples random dose1 effects (slopes) and lab effects (intercepts) from our final mixed model, holding all other predictors constant, and plots the resulting dose effect curve. 
```{r fig6, fig.height=51, fig.width=15, fig.cap="Dose 1 Response Curves for Each Lab", }

par(mfrow = c(7,3))
for(eachlab in unique(dat$lab)){
  simdose1curves(m3, 100, expsq, eachlab)
}
par(mfrow = c(1,1))
```

<!--
account for correlation using multivariate normal.
use 2 dimensional mvnorm for slope and intercept.
just plug in average values for everything else.
-->

### Discussion

The variance in the dose1 effects by lab is noticeably high, so we say that the bioassay does depend on lab and thus this study fails miserably. 

This explodes around 10 and it's only applicable for dose less than or equal to 10.

### Contributions

Nathaniel Brown made the visualizations for this report. He also organized the relevant files in a Github repository for the group to access and edit. Annie Tang compiled the group work done on EDA into a .rmd and wrote the accompanying explanations for the EDA and approaches to analysis. William Yang helped pair on EDA analysis and identify approaches to handle the data. Approaches to analysis were a joint effort by all members of the group. Nathanial implemented analysis for the univariate normal and multivariate normal approaches. Implementation and analysis of the mixed effects model was a joint effort by all members of the group. 

